#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½ ONNX åŠ è½½å™¨

å®ç°æ™ºèƒ½çš„ ONNX æ¨¡å‹åŠ è½½ï¼Œè‡ªåŠ¨å¤„ç†åŠ å¯†/éåŠ å¯†æ¨¡å‹ã€‚
éµå¾ª Linux å†…æ ¸çš„è®¾å¤‡é©±åŠ¨æ¨¡å‹è®¾è®¡ã€‚
"""

import os
import tempfile
import atexit
from pathlib import Path
from ..core.crypto import AESCrypto
from ..core.auth import AuthManager
from ..core.errors import LoaderError, DecryptionError

try:
    import onnxruntime as ort
except ImportError:
    print("âš ï¸ onnxruntime æœªå®‰è£…ï¼ŒONNX åŠ è½½å™¨åŠŸèƒ½å°†ä¸å¯ç”¨")
    ort = None


class SmartONNXLoader:
    """æ™ºèƒ½ ONNX åŠ è½½å™¨
    
    è‡ªåŠ¨å¤„ç†åŠ å¯†å’ŒéåŠ å¯†çš„ ONNX æ¨¡å‹åŠ è½½ã€‚
    å®ç°äº†å®Œå…¨é€æ˜çš„åŠ å¯†æ¨¡å‹åŠ è½½æœºåˆ¶ã€‚
    """
    
    def __init__(self):
        """åˆå§‹åŒ– ONNX åŠ è½½å™¨"""
        if ort is None:
            raise LoaderError("onnxruntime æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨ ONNX åŠ è½½å™¨")
        
        self.crypto = AESCrypto()
        self.auth_manager = AuthManager()
        self._temp_files = set()
        self._model_cache = {}  # æ¨¡å‹ä¼šè¯ç¼“å­˜
        self._original_inference_session = ort.InferenceSession
        
        # æ³¨å†Œé€€å‡ºæ—¶æ¸…ç†
        atexit.register(self.cleanup_all)
    
    def load_model(self, model_path, **kwargs):
        """æ™ºèƒ½åŠ è½½æ¨¡å‹
        
        è‡ªåŠ¨åˆ¤æ–­æ¨¡å‹æ˜¯å¦åŠ å¯†ï¼Œé€‰æ‹©åˆé€‚çš„åŠ è½½æ–¹å¼ã€‚
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            **kwargs: ä¼ é€’ç»™ InferenceSession çš„å‚æ•°
            
        Returns:
            onnxruntime.InferenceSession: æ¨ç†ä¼šè¯
        """
        try:
            # 1. æ£€æŸ¥æ˜¯å¦æ˜¯å·²çŸ¥çš„åŠ å¯†æ¨¡å‹
            if self._is_known_encrypted_model(model_path):
                return self._load_encrypted_model(model_path, **kwargs)
            
            # 2. è‡ªåŠ¨å‘ç°åŠ å¯†ç‰ˆæœ¬
            encrypted_path = self._discover_encrypted_version(model_path)
            if encrypted_path:
                print(f"ğŸ” è‡ªåŠ¨å‘ç°åŠ å¯†æ¨¡å‹: {model_path} -> {encrypted_path}")
                return self._load_encrypted_model(encrypted_path, **kwargs)
            
            # 3. é™çº§åˆ°æ™®é€šåŠ è½½
            print(f"ğŸ“¦ ä½¿ç”¨æ™®é€šåŠ è½½: {model_path}")
            return self._original_inference_session(model_path, **kwargs)
            
        except Exception as e:
            raise LoaderError(f"åŠ è½½æ¨¡å‹å¤±è´¥ {model_path}: {e}")
    
    def _is_known_encrypted_model(self, model_path):
        """æ£€æŸ¥æ˜¯å¦æ˜¯å·²çŸ¥çš„åŠ å¯†æ¨¡å‹
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦æ˜¯åŠ å¯†æ¨¡å‹
        """
        return (model_path.endswith('.encrypt') or 
                '.encrypt' in model_path or
                model_path.endswith('.enc') or
                model_path in self._model_cache)
    
    def _discover_encrypted_version(self, model_path):
        """è‡ªåŠ¨å‘ç°åŠ å¯†ç‰ˆæœ¬
        
        Args:
            model_path: åŸå§‹æ¨¡å‹è·¯å¾„
            
        Returns:
            str: åŠ å¯†æ¨¡å‹è·¯å¾„ï¼Œæœªæ‰¾åˆ°è¿”å› None
        """
        model_path_obj = Path(model_path)
        
        # æ£€æŸ¥åŒç›®å½•ä¸‹çš„å„ç§åŠ å¯†ç‰ˆæœ¬
        possible_encrypted_paths = [
            # æ ‡å‡†åŠ å¯†æ‰©å±•å
            model_path_obj.with_suffix('.onnx.encrypt'),
            model_path_obj.with_suffix('.encrypt'),
            model_path_obj.with_suffix('.enc'),
            
            # åŒååŠ å¯†æ–‡ä»¶
            model_path_obj.parent / f"{model_path_obj.stem}.encrypt",
            model_path_obj.parent / f"{model_path_obj.stem}.onnx.encrypt",
            model_path_obj.parent / f"{model_path_obj.stem}.enc",
            
            # åŠ å¯†ç›®å½•ä¸­çš„æ–‡ä»¶
            model_path_obj.parent / 'encrypted' / model_path_obj.name,
            model_path_obj.parent / 'encrypted' / f"{model_path_obj.name}.encrypt",
        ]
        
        for encrypted_path in possible_encrypted_paths:
            if encrypted_path.exists():
                return str(encrypted_path)
        
        return None
    
    def _load_encrypted_model(self, encrypted_path, **kwargs):
        """åŠ è½½åŠ å¯†æ¨¡å‹
        
        Args:
            encrypted_path: åŠ å¯†æ¨¡å‹è·¯å¾„
            **kwargs: ä¼ é€’ç»™ InferenceSession çš„å‚æ•°
            
        Returns:
            onnxruntime.InferenceSession: æ¨ç†ä¼šè¯
        """
        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"{encrypted_path}:{hash(str(sorted(kwargs.items())))}"
            if cache_key in self._model_cache:
                print(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„æ¨¡å‹ä¼šè¯: {encrypted_path}")
                return self._model_cache[cache_key]
            
            # è·å–åŠ å¯†å¯†é’¥
            encryption_key = self.auth_manager.get_key()
            
            # è§£å¯†æ¨¡å‹åˆ°å†…å­˜
            decrypted_model = self.crypto.decrypt_file(encrypted_path, encryption_key)
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            tmp_file = tempfile.NamedTemporaryFile(
                delete=False, 
                suffix='.onnx',
                prefix='decrypted_model_'
            )
            tmp_file.write(decrypted_model)
            tmp_file.close()
            
            self._temp_files.add(tmp_file.name)
            
            # åˆ›å»ºæ¨ç†ä¼šè¯
            session = self._original_inference_session(tmp_file.name, **kwargs)
            
            # ç¼“å­˜ä¼šè¯
            self._model_cache[cache_key] = session
            
            # å°†æ¸…ç†æ–¹æ³•é™„åŠ åˆ°ä¼šè¯
            session._encrypted_temp_file = tmp_file.name
            session._cleanup = lambda: self._cleanup_file(tmp_file.name)
            
            print(f"âœ… æˆåŠŸåŠ è½½åŠ å¯†æ¨¡å‹: {encrypted_path}")
            return session
            
        except Exception as e:
            raise LoaderError(f"åŠ è½½åŠ å¯†æ¨¡å‹å¤±è´¥ {encrypted_path}: {e}")
    
    def _cleanup_file(self, tmp_file):
        """æ¸…ç†å•ä¸ªä¸´æ—¶æ–‡ä»¶
        
        Args:
            tmp_file: ä¸´æ—¶æ–‡ä»¶è·¯å¾„
        """
        if tmp_file in self._temp_files:
            try:
                os.unlink(tmp_file)
                self._temp_files.remove(tmp_file)
                print(f"ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {os.path.basename(tmp_file)}")
            except Exception as e:
                print(f"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥ {tmp_file}: {e}")
    
    def cleanup_all(self):
        """æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶"""
        temp_count = len(self._temp_files)
        for tmp_file in list(self._temp_files):
            self._cleanup_file(tmp_file)
        
        if temp_count > 0:
            print(f"ğŸ§¹ æ¸…ç†äº† {temp_count} ä¸ªä¸´æ—¶æ–‡ä»¶")
    
    def get_cache_info(self):
        """è·å–ç¼“å­˜ä¿¡æ¯
        
        Returns:
            dict: ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        """
        return {
            'cached_models': len(self._model_cache),
            'temp_files': len(self._temp_files),
            'cache_keys': list(self._model_cache.keys()),
            'temp_file_paths': list(self._temp_files)
        }
    
    def clear_cache(self):
        """æ¸…ç†æ¨¡å‹ç¼“å­˜"""
        self._model_cache.clear()
        print("ğŸ§¹ æ¨¡å‹ç¼“å­˜å·²æ¸…ç†")


class ONNXLoaderManager:
    """ONNX åŠ è½½å™¨ç®¡ç†å™¨
    
    ç®¡ç†æ™ºèƒ½ ONNX åŠ è½½å™¨çš„ç”Ÿå‘½å‘¨æœŸã€‚
    """
    
    def __init__(self):
        self.loader = None
        self._is_patched = False
    
    def install_loader(self):
        """å®‰è£…æ™ºèƒ½ ONNX åŠ è½½å™¨"""
        try:
            if ort is None:
                print("âš ï¸ onnxruntime æœªå®‰è£…ï¼Œè·³è¿‡ ONNX åŠ è½½å™¨å®‰è£…")
                return None
            
            self.loader = SmartONNXLoader()
            
            # æ›¿æ¢ InferenceSession
            ort.InferenceSession = self.loader.load_model
            self._is_patched = True
            
            print("ğŸš€ æ™ºèƒ½ ONNX åŠ è½½å™¨å·²å®‰è£…")
            print("ğŸ¯ ç³»ç»Ÿå°†è‡ªåŠ¨å¤„ç†åŠ å¯†/éåŠ å¯†æ¨¡å‹")
            
            return self.loader
            
        except Exception as e:
            raise LoaderError(f"å®‰è£… ONNX åŠ è½½å™¨å¤±è´¥: {e}")
    
    def uninstall_loader(self):
        """å¸è½½æ™ºèƒ½ ONNX åŠ è½½å™¨"""
        try:
            if self.loader and self._is_patched:
                ort.InferenceSession = self.loader._original_inference_session
                self._is_patched = False
                print("âŒ æ™ºèƒ½ ONNX åŠ è½½å™¨å·²å¸è½½")
            
            if self.loader:
                self.loader.cleanup_all()
                self.loader = None
            
        except Exception as e:
            print(f"âš ï¸ å¸è½½ ONNX åŠ è½½å™¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    def get_loader(self):
        """è·å–åŠ è½½å™¨å®ä¾‹
        
        Returns:
            SmartONNXLoader: åŠ è½½å™¨å®ä¾‹
        """
        return self.loader
    
    def is_installed(self):
        """æ£€æŸ¥åŠ è½½å™¨æ˜¯å¦å·²å®‰è£…
        
        Returns:
            bool: æ˜¯å¦å·²å®‰è£…
        """
        return self.loader is not None and self._is_patched
